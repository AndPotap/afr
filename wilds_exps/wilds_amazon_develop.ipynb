{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from wilds import get_dataset\n",
    "# from wilds.common.data_loaders import get_train_loader\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "import transforms\n",
    "# from transforms import \n",
    "\n",
    "from types import SimpleNamespace\n",
    "from wilds_configs.utils import populate_defaults\n",
    "from wilds_configs import datasets as dataset_configs\n",
    "from wilds_configs import model as model_configs\n",
    "\n",
    "from wilds.datasets.wilds_dataset import WILDSSubset\n",
    "\n",
    "from wilds_models.initializer import initialize_model\n",
    "from wilds_algorithms.initializer import infer_d_out\n",
    "# import configs\n",
    "# from configs.datasets import dataset_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    algorithm='ERM',\n",
    "    load_featurizer_only=False,\n",
    "    pretrained_model_path=None,\n",
    "    **dataset_configs.dataset_defaults[\"amazon\"],\n",
    "    )\n",
    "config.model_kwargs = {}\n",
    "# config = populate_defaults(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset=\"amazon\", download=False,\n",
    "                      root_dir='/datasets/')\n",
    "#                       root_dir='/home/pavel/datasets/')\n",
    "\n",
    "transform = transforms.initialize_transform(\n",
    "        transform_name='bert',\n",
    "        config=config,\n",
    "        dataset=dataset,\n",
    "        additional_transform_name=None,\n",
    "        is_training=True)\n",
    "\n",
    "train_data = dataset.get_subset(\n",
    "        \"train\",\n",
    "        frac=1.,\n",
    "        transform=transform)\n",
    "\n",
    "# Get the test set\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\", transform=transform\n",
    ")\n",
    "val_data = dataset.get_subset(\n",
    "    \"val\", transform=transform\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 0\n",
    "# idx = train_data.indices.copy()\n",
    "# rng = np.random.default_rng(0)\n",
    "# rng.shuffle(idx)\n",
    "# n_train = int((1 - 0.2) * len(idx))\n",
    "# train_idx = idx[:n_train]\n",
    "# val_idx = idx[n_train:]\n",
    "\n",
    "# val_data = WILDSSubset(\n",
    "#     dataset,\n",
    "#     indices=val_idx,\n",
    "#     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertClassifier: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_model(config=config, d_out=infer_d_out(train_data, config))\n",
    "# ckpt_dict = torch.load('ckpts/civilcomments_seed_0_epoch_last_model.pth')\n",
    "ckpt_dict = torch.load('logs/amazon_seed:0_epoch:last_model.pth')\n",
    "model.load_state_dict({k[len('model.'):]: v for (k, v) in ckpt_dict['algorithm'].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader(\n",
    "        loader=\"standard\",\n",
    "        dataset=train_data,\n",
    "        batch_size=16,\n",
    "        uniform_over_groups=False,\n",
    "        grouper=None,\n",
    "        distinct_groups=False,\n",
    "        n_groups_per_batch=None)\n",
    "\n",
    "# Prepare the evaluation data loader\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6254/6254 [10:10<00:00, 10.25it/s]\n"
     ]
    }
   ],
   "source": [
    "all_y_pred, all_y_true, all_metadata = [], [], []\n",
    "with torch.no_grad():\n",
    "    for x, y_true, metadata in tqdm.tqdm(test_loader):\n",
    "        y_pred = model(x.cuda())\n",
    "        all_y_pred.append(y_pred.cpu())\n",
    "        all_y_true.append(y_true.cpu())\n",
    "        all_metadata.append(metadata)\n",
    "        # break\n",
    "all_y_pred = torch.cat(all_y_pred, axis=0)\n",
    "all_y_true = torch.cat(all_y_true, axis=0)\n",
    "all_metadata = torch.cat(all_metadata, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.719\n",
      "10th percentile acc: 0.533\n",
      "Worst-group acc: 0.120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(torch.argmax(all_y_pred, axis=1), all_y_true, all_metadata)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFR-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, loader):\n",
    "    all_embeddings, all_y_true, all_metadata = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y_true, metadata in tqdm.tqdm(loader):\n",
    "            embeddings = model(x.cuda())\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_y_true.append(y_true.cpu())\n",
    "            all_metadata.append(metadata)\n",
    "            # break\n",
    "    all_embeddings = torch.cat(all_embeddings, axis=0)\n",
    "    all_y_true = torch.cat(all_y_true, axis=0)\n",
    "    all_metadata = torch.cat(all_metadata, axis=0)\n",
    "    return all_embeddings, all_y_true, all_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from dfr import dfr_tune, dfr_run, dfr_tune_and_run, dfr_predict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = get_eval_loader(\"standard\", val_data, batch_size=16)\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Identity(model.classifier.in_features)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6254/6254 [10:09<00:00, 10.27it/s]\n",
      "100%|██████████| 6254/6254 [10:12<00:00, 10.21it/s]\n"
     ]
    }
   ],
   "source": [
    "val_embeddings, val_y_true, val_metadata = get_embeddings(model, val_loader)\n",
    "test_embeddings, test_y_true, test_metadata = get_embeddings(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user', 'product', 'category', 'year', 'y', 'from_source_domain']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.metadata_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1413,  2886,  9315, 27908, 58528])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bincount(val_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1573,     0,     0,    18,     4,     0],\n",
       "        [ 1573,     0,     0,    17,     4,     0],\n",
       "        [ 2300, 62111,     0,    21,     4,     0],\n",
       "        ...,\n",
       "        [ 2011, 62120,    23,    20,     3,     0],\n",
       "        [ 2491, 62099,    23,    21,     4,     0],\n",
       "        [ 1492, 62234,    23,    22,     4,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_spurious = val_metadata[:, :8]\n",
    "val_groups = val_y_true\n",
    "\n",
    "# test_spurious = test_metadata[:, :8]\n",
    "test_groups = test_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: [0.64637681 0.49566955 0.51955911 0.50244534 0.70095212]\n",
      "0.7: [0.66956522 0.50566289 0.52280095 0.52574799 0.71920964]\n",
      "0.3: [0.69855072 0.52298468 0.52863627 0.53984465 0.75756748]\n",
      "0.1: [0.70724638 0.54230513 0.57380592 0.55221519 0.75551991]\n",
      "0.07: [0.71304348 0.5236509  0.56559326 0.55336594 0.79445791]\n",
      "0.03: [0.74492754 0.51165889 0.5612708  0.58119965 0.77169573]\n",
      "0.01: [0.71304348 0.49900067 0.6001729  0.56300345 0.78036379]\n",
      "Training model 0/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 1/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 2/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 3/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 4/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 5/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 6/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 7/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 8/10, group counts: [1413 1413 1413 1413 1413]\n",
      "Training model 9/10, group counts: [1413 1413 1413 1413 1413]\n"
     ]
    }
   ],
   "source": [
    "logreg, scaler = dfr_tune_and_run(val_embeddings, val_y_true, val_groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.682\n",
      "10th percentile acc: 0.507\n",
      "Worst-group acc: 0.147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6835), tensor(0.5342), tensor(0.5681), tensor(0.5678)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(test_preds == test_y_true)[test_groups == g].float().mean() for g in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_counts = val_metadata[:, :8].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1293, 1677, 1993, 2755, 3395, 5182, 5980, 7199])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_ordering = torch.argsort(identity_counts)\n",
    "identity_counts[identity_ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other_religions',\n",
       " 'LGBTQ',\n",
       " 'black',\n",
       " 'muslim',\n",
       " 'white',\n",
       " 'christian',\n",
       " 'male',\n",
       " 'female']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset.metadata_fields[i] for i in identity_ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata_ordered = val_metadata[:, :8].T[identity_ordering].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29762,  2576,  1092,   201,  1159,   466,  1257,   584,  1843,   460,\n",
       "         1805,   624,  3750,   258,  3703,   505,  3285,   478])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = torch.argmax(torch.cat(\n",
    "        [torch.zeros((len(val_metadata_ordered),))[:, None], val_metadata_ordered], axis=1), axis=1)\n",
    "groups = groups * 2 + val_y_true\n",
    "torch.bincount(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: [0.87688172 0.76870229 0.78531073 0.67       0.70630631 0.69294606\n",
      " 0.64548495 0.70989761 0.72777778 0.69135802 0.74215247 0.72360248\n",
      " 0.88296761 0.68644068 0.81550218 0.75875486 0.82639715 0.77118644]\n",
      "0.7: [0.87627688 0.81145038 0.72693032 0.78       0.67747748 0.67219917\n",
      " 0.71070234 0.67918089 0.73666667 0.74485597 0.76457399 0.72670807\n",
      " 0.88087774 0.71186441 0.84224891 0.77042802 0.84423306 0.76271186]\n",
      "0.3: [0.8874328  0.8389313  0.81544256 0.68       0.73693694 0.70124481\n",
      " 0.71404682 0.73037543 0.72888889 0.72427984 0.70852018 0.77639752\n",
      " 0.88035528 0.74576271 0.84497817 0.79766537 0.84661118 0.76694915]\n",
      "0.1: [0.90658602 0.85801527 0.80225989 0.75       0.73513514 0.77593361\n",
      " 0.68561873 0.78498294 0.73       0.79835391 0.73206278 0.81055901\n",
      " 0.90125392 0.74576271 0.85480349 0.82879377 0.86444709 0.81779661]\n",
      "0.07: [0.89603495 0.87022901 0.7740113  0.78       0.72792793 0.76763485\n",
      " 0.68729097 0.77474403 0.71555556 0.8436214  0.66928251 0.86956522\n",
      " 0.89341693 0.80508475 0.83296943 0.84435798 0.85255648 0.8220339 ]\n",
      "0.03: [0.9186828  0.84122137 0.80225989 0.81       0.69369369 0.81742739\n",
      " 0.68729097 0.78498294 0.76       0.781893   0.70964126 0.84161491\n",
      " 0.91065831 0.74576271 0.84606987 0.85214008 0.84601665 0.83050847]\n",
      "0.01: [0.90678763 0.84961832 0.81920904 0.73       0.77297297 0.76348548\n",
      " 0.73578595 0.76791809 0.76222222 0.80658436 0.72533632 0.82919255\n",
      " 0.91065831 0.73728814 0.84334061 0.84824903 0.8489893  0.83474576]\n",
      "Training model 0/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 1/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 2/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 3/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 4/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 5/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 6/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 7/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 8/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 9/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n"
     ]
    }
   ],
   "source": [
    "logreg, scaler = dfr_tune_and_run(val_embeddings, val_y_true, groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.872\n",
      "  male                   acc on non_toxic: 0.834 (n =  12092)    acc on toxic: 0.801 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.848 (n =  14179)    acc on toxic: 0.800 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.719 (n =   3210)    acc on toxic: 0.760 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.878 (n =  12101)    acc on toxic: 0.781 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.758 (n =   5355)    acc on toxic: 0.757 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.823 (n =   2980)    acc on toxic: 0.771 (n =    520) \n",
      "  black                  acc on non_toxic: 0.722 (n =   3335)    acc on toxic: 0.774 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.717 (n =   5723)    acc on toxic: 0.793 (n =   2246) \n",
      "Worst-group acc: 0.717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.872\n",
      "  male                   acc on non_toxic: 0.830 (n =   5076)    acc on toxic: 0.798 (n =    904) \n",
      "  female                 acc on non_toxic: 0.841 (n =   6208)    acc on toxic: 0.818 (n =    991) \n",
      "  LGBTQ                  acc on non_toxic: 0.746 (n =   1199)    acc on toxic: 0.789 (n =    478) \n",
      "  christian              acc on non_toxic: 0.884 (n =   4709)    acc on toxic: 0.763 (n =    473) \n",
      "  muslim                 acc on non_toxic: 0.761 (n =   2160)    acc on toxic: 0.797 (n =    595) \n",
      "  other_religions        acc on non_toxic: 0.836 (n =   1092)    acc on toxic: 0.781 (n =    201) \n",
      "  black                  acc on non_toxic: 0.728 (n =   1349)    acc on toxic: 0.758 (n =    644) \n",
      "  white                  acc on non_toxic: 0.728 (n =   2446)    acc on toxic: 0.800 (n =    949) \n",
      "Worst-group acc: 0.728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(val_preds, val_y_true, val_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9103),\n",
       " tensor(0.8560),\n",
       " tensor(0.8361),\n",
       " tensor(0.7811),\n",
       " tensor(0.7463),\n",
       " tensor(0.7876),\n",
       " tensor(0.7367),\n",
       " tensor(0.7603)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(val_preds == val_y_true)[groups == g].float().mean() for g in range(8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.get_subset(\n",
    "        \"train\",\n",
    "        frac=1.,\n",
    "        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269038"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.indices.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1108, 0.1347, 0.0313, 0.0994, 0.0519, 0.0243, 0.0368, 0.0621])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.metadata_array[:, :8].float().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d036ee486502f125a4c1259b255120961e3edf906e0a2d0ed5ed690d7b67e113"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
