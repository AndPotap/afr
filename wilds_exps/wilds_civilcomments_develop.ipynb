{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 00:48:56.401551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-27 00:48:56.530890: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-27 00:48:57.076104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/usr/local/cuda-11.0/lib64\n",
      "2022-09-27 00:48:57.076147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/usr/local/cuda-11.0/lib64\n",
      "2022-09-27 00:48:57.076152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from wilds import get_dataset\n",
    "# from wilds.common.data_loaders import get_train_loader\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "import transforms\n",
    "# from transforms import \n",
    "\n",
    "from types import SimpleNamespace\n",
    "from wilds_configs.utils import populate_defaults\n",
    "from wilds_configs import datasets as dataset_configs\n",
    "from wilds_configs import model as model_configs\n",
    "\n",
    "from wilds.datasets.wilds_dataset import WILDSSubset\n",
    "\n",
    "from wilds_models.initializer import initialize_model\n",
    "from wilds_algorithms.initializer import infer_d_out\n",
    "# import configs\n",
    "# from configs.datasets import dataset_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    algorithm='ERM',\n",
    "    load_featurizer_only=False,\n",
    "    pretrained_model_path=None,\n",
    "    **dataset_configs.dataset_defaults[\"civilcomments\"],\n",
    "    )\n",
    "config.model_kwargs = {}\n",
    "# config = populate_defaults(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset=\"civilcomments\", download=False,\n",
    "                    #   root_dir='/data/users/pavel_i/datasets/')\n",
    "                      root_dir='/home/pavel/datasets/')\n",
    "\n",
    "transform = transforms.initialize_transform(\n",
    "        transform_name='bert',\n",
    "        config=config,\n",
    "        dataset=dataset,\n",
    "        additional_transform_name=None,\n",
    "        is_training=True)\n",
    "\n",
    "train_data = dataset.get_subset(\n",
    "        \"train\",\n",
    "        frac=1.,\n",
    "        transform=transform)\n",
    "\n",
    "# Get the test set\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\", transform=transform\n",
    ")\n",
    "original_val_data = dataset.get_subset(\n",
    "    \"val\", transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "idx = train_data.indices.copy()\n",
    "rng = np.random.default_rng(0)\n",
    "rng.shuffle(idx)\n",
    "n_train = int((1 - 0.2) * len(idx))\n",
    "train_idx = idx[:n_train]\n",
    "val_idx = idx[n_train:]\n",
    "\n",
    "val_data = WILDSSubset(\n",
    "    dataset,\n",
    "    indices=val_idx,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wilds.datasets.wilds_dataset.WILDSSubset at 0x7feebee3c760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertClassifier: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_model(config=config, d_out=infer_d_out(train_data, config))\n",
    "ckpt_dict = torch.load('ckpts/civilcomments_seed_0_epoch_last_model.pth')\n",
    "# ckpt_dict = torch.load('logs/civilcomments_dfrdrop_0/civilcomments_seed:0_epoch:last_model.pth')\n",
    "model.load_state_dict({k[len('model.'):]: v for (k, v) in ckpt_dict['algorithm'].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader(\n",
    "        loader=\"standard\",\n",
    "        dataset=train_data,\n",
    "        batch_size=16,\n",
    "        uniform_over_groups=False,\n",
    "        grouper=None,\n",
    "        distinct_groups=False,\n",
    "        n_groups_per_batch=None)\n",
    "\n",
    "# Prepare the evaluation data loader\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8362/8362 [07:38<00:00, 18.25it/s]\n"
     ]
    }
   ],
   "source": [
    "all_y_pred, all_y_true, all_metadata = [], [], []\n",
    "with torch.no_grad():\n",
    "    for x, y_true, metadata in tqdm.tqdm(test_loader):\n",
    "        y_pred = model(x.cuda())\n",
    "        all_y_pred.append(y_pred.cpu())\n",
    "        all_y_true.append(y_true.cpu())\n",
    "        all_metadata.append(metadata)\n",
    "        # break\n",
    "all_y_pred = torch.cat(all_y_pred, axis=0)\n",
    "all_y_true = torch.cat(all_y_true, axis=0)\n",
    "all_metadata = torch.cat(all_metadata, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.920\n",
      "  male                   acc on non_toxic: 0.938 (n =  12092)    acc on toxic: 0.615 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.944 (n =  14179)    acc on toxic: 0.606 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.874 (n =   3210)    acc on toxic: 0.581 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.959 (n =  12101)    acc on toxic: 0.561 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.899 (n =   5355)    acc on toxic: 0.565 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.933 (n =   2980)    acc on toxic: 0.567 (n =    520) \n",
      "  black                  acc on non_toxic: 0.846 (n =   3335)    acc on toxic: 0.645 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.855 (n =   5723)    acc on toxic: 0.643 (n =   2246) \n",
      "Worst-group acc: 0.561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(torch.argmax(all_y_pred, axis=1), all_y_true, all_metadata)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFR-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, loader):\n",
    "    all_embeddings, all_y_true, all_metadata = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y_true, metadata in tqdm.tqdm(loader):\n",
    "            embeddings = model(x.cuda())\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_y_true.append(y_true.cpu())\n",
    "            all_metadata.append(metadata)\n",
    "            # break\n",
    "    all_embeddings = torch.cat(all_embeddings, axis=0)\n",
    "    all_y_true = torch.cat(all_y_true, axis=0)\n",
    "    all_metadata = torch.cat(all_metadata, axis=0)\n",
    "    return all_embeddings, all_y_true, all_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from dfr import dfr_tune, dfr_run, dfr_tune_and_run, dfr_predict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = get_eval_loader(\"standard\", val_data, batch_size=16)\n",
    "original_val_loader = get_eval_loader(\"standard\", original_val_data, batch_size=16)\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Identity(model.classifier.in_features)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3363/3363 [03:04<00:00, 18.25it/s]\n",
      "100%|██████████| 2824/2824 [02:34<00:00, 18.23it/s]\n",
      "100%|██████████| 8362/8362 [07:38<00:00, 18.24it/s]\n"
     ]
    }
   ],
   "source": [
    "val_embeddings, val_y_true, val_metadata = get_embeddings(model, val_loader)\n",
    "original_val_embeddings, original_val_y_true, original_val_metadata = get_embeddings(model, original_val_loader)\n",
    "test_embeddings, test_y_true, test_metadata = get_embeddings(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.metadata_fields[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46307,  1349,  5508,   644])\n"
     ]
    }
   ],
   "source": [
    "val_spurious = val_metadata[:, 6]\n",
    "val_groups = val_y_true * 2 + val_spurious\n",
    "print(torch.bincount(val_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: [0.82393819 0.66034985 0.77512839 0.67901235]\n",
      "0.7: [0.83149171 0.62973761 0.80190756 0.67592593]\n",
      "0.3: [0.86390711 0.67346939 0.83015407 0.70061728]\n",
      "0.1: [0.8660221  0.66180758 0.83345561 0.77777778]\n",
      "0.07: [0.8917904  0.70553936 0.81731475 0.80246914]\n",
      "0.03: [0.87007942 0.696793   0.83895818 0.7962963 ]\n",
      "0.01: [0.87357562 0.74927114 0.82978723 0.79012346]\n",
      "Training model 0/10, group counts: [644 644 644 644]\n",
      "Training model 1/10, group counts: [644 644 644 644]\n",
      "Training model 2/10, group counts: [644 644 644 644]\n",
      "Training model 3/10, group counts: [644 644 644 644]\n",
      "Training model 4/10, group counts: [644 644 644 644]\n",
      "Training model 5/10, group counts: [644 644 644 644]\n",
      "Training model 6/10, group counts: [644 644 644 644]\n",
      "Training model 7/10, group counts: [644 644 644 644]\n",
      "Training model 8/10, group counts: [644 644 644 644]\n",
      "Training model 9/10, group counts: [644 644 644 644]\n"
     ]
    }
   ],
   "source": [
    "logreg, scaler = dfr_tune_and_run(val_embeddings, val_y_true, val_groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.882\n",
      "  male                   acc on non_toxic: 0.837 (n =  12092)    acc on toxic: 0.798 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.845 (n =  14179)    acc on toxic: 0.806 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.677 (n =   3210)    acc on toxic: 0.799 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.890 (n =  12101)    acc on toxic: 0.781 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.742 (n =   5355)    acc on toxic: 0.784 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.831 (n =   2980)    acc on toxic: 0.773 (n =    520) \n",
      "  black                  acc on non_toxic: 0.737 (n =   3335)    acc on toxic: 0.768 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.723 (n =   5723)    acc on toxic: 0.793 (n =   2246) \n",
      "Worst-group acc: 0.677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9270), tensor(0.8303), tensor(0.8288), tensor(0.7917)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(test_preds == test_y_true)[test_groups == g].float().mean() for g in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_spurious = val_metadata[:, :8]\n",
    "val_spurious = torch.any(val_spurious, dim=1).int()\n",
    "val_groups = val_y_true * 2 + val_spurious\n",
    "\n",
    "test_spurious = test_metadata[:, :8]\n",
    "test_spurious = torch.any(test_spurious, dim=1).int()\n",
    "test_groups = test_y_true * 2 + test_spurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: [0.8883061  0.7869163  0.81951975 0.79423403]\n",
      "0.7: [0.89395468 0.7844645  0.81719597 0.77953646]\n",
      "0.3: [0.89751866 0.78925666 0.85127808 0.81797626]\n",
      "0.1: [0.89745142 0.77922657 0.86676995 0.85245902]\n",
      "0.07: [0.89482886 0.77621754 0.8721921  0.85867722]\n",
      "0.03: [0.9002757  0.76774769 0.86986832 0.86037309]\n",
      "0.01: [0.89489611 0.76707901 0.88148722 0.86319955]\n",
      "Training model 0/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 1/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 2/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 3/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 4/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 5/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 6/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 7/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 8/10, group counts: [2576 2576 2576 2576]\n",
      "Training model 9/10, group counts: [2576 2576 2576 2576]\n"
     ]
    }
   ],
   "source": [
    "logreg, scaler = dfr_tune_and_run(val_embeddings, val_y_true, val_groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, logreg, scaler))\n",
    "original_val_preds = torch.from_numpy(dfr_predict(original_val_embeddings, custom_logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.855\n",
      "  male                   acc on non_toxic: 0.805 (n =  12092)    acc on toxic: 0.842 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.837 (n =  14179)    acc on toxic: 0.811 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.600 (n =   3210)    acc on toxic: 0.870 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.875 (n =  12101)    acc on toxic: 0.800 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.688 (n =   5355)    acc on toxic: 0.829 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.787 (n =   2980)    acc on toxic: 0.827 (n =    520) \n",
      "  black                  acc on non_toxic: 0.542 (n =   3335)    acc on toxic: 0.886 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.594 (n =   5723)    acc on toxic: 0.876 (n =   2246) \n",
      "Worst-group acc: 0.542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.8949), tensor(0.7857), tensor(0.8841), tensor(0.8468)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(test_preds == test_y_true)[test_groups == g].float().mean() for g in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_logreg = copy.deepcopy(logreg)\n",
    "custom_logreg.intercept_ -= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, custom_logreg, scaler))\n",
    "original_val_preds = torch.from_numpy(dfr_predict(original_val_embeddings, custom_logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, custom_logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.886\n",
      "  male                   acc on non_toxic: 0.847 (n =   4050)    acc on toxic: 0.832 (n =    715) \n",
      "  female                 acc on non_toxic: 0.848 (n =   5120)    acc on toxic: 0.825 (n =    771) \n",
      "  LGBTQ                  acc on non_toxic: 0.698 (n =   1099)    acc on toxic: 0.782 (n =    358) \n",
      "  christian              acc on non_toxic: 0.912 (n =   4166)    acc on toxic: 0.721 (n =    384) \n",
      "  muslim                 acc on non_toxic: 0.743 (n =   1598)    acc on toxic: 0.781 (n =    512) \n",
      "  other_religions        acc on non_toxic: 0.829 (n =    824)    acc on toxic: 0.691 (n =    162) \n",
      "  black                  acc on non_toxic: 0.724 (n =   1119)    acc on toxic: 0.790 (n =    533) \n",
      "  white                  acc on non_toxic: 0.711 (n =   2015)    acc on toxic: 0.783 (n =    852) \n",
      "Worst-group acc: 0.691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(original_val_preds, original_val_y_true, original_val_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.883\n",
      "  male                   acc on non_toxic: 0.838 (n =  12092)    acc on toxic: 0.797 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.847 (n =  14179)    acc on toxic: 0.804 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.680 (n =   3210)    acc on toxic: 0.798 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.891 (n =  12101)    acc on toxic: 0.776 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.747 (n =   5355)    acc on toxic: 0.781 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.833 (n =   2980)    acc on toxic: 0.771 (n =    520) \n",
      "  black                  acc on non_toxic: 0.739 (n =   3335)    acc on toxic: 0.764 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.725 (n =   5723)    acc on toxic: 0.790 (n =   2246) \n",
      "Worst-group acc: 0.680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_logreg = copy.deepcopy(logreg)\n",
    "custom_logreg.intercept_ -= 0.1\n",
    "\n",
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, custom_logreg, scaler))\n",
    "original_val_preds = torch.from_numpy(dfr_predict(original_val_embeddings, custom_logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, custom_logreg, scaler))\n",
    "\n",
    "print(dataset.eval(original_val_preds, original_val_y_true, original_val_metadata)[-1])\n",
    "\n",
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_counts = val_metadata[:, :8].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1293, 1677, 1993, 2755, 3395, 5182, 5980, 7199])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_ordering = torch.argsort(identity_counts)\n",
    "identity_counts[identity_ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other_religions',\n",
       " 'LGBTQ',\n",
       " 'black',\n",
       " 'muslim',\n",
       " 'white',\n",
       " 'christian',\n",
       " 'male',\n",
       " 'female']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset.metadata_fields[i] for i in identity_ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata_ordered = val_metadata[:, :8].T[identity_ordering].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29762,  2576,  1092,   201,  1159,   466,  1257,   584,  1843,   460,\n",
       "         1805,   624,  3750,   258,  3703,   505,  3285,   478])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = torch.argmax(torch.cat(\n",
    "        [torch.zeros((len(val_metadata_ordered),))[:, None], val_metadata_ordered], axis=1), axis=1)\n",
    "groups = groups * 2 + val_y_true\n",
    "torch.bincount(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: [0.88929293 0.80061586 0.79118774 0.75531915 0.70819113 0.71487603\n",
      " 0.71186441 0.72697368 0.70171674 0.73305085 0.68574635 0.73968254\n",
      " 0.85957447 0.70542636 0.82158351 0.77777778 0.83695652 0.71551724]\n",
      "0.7: [0.89279461 0.79368745 0.77203065 0.76595745 0.71672355 0.70247934\n",
      " 0.72265023 0.69078947 0.70493562 0.75847458 0.72615039 0.78412698\n",
      " 0.87819149 0.75193798 0.84598698 0.75720165 0.83031401 0.80172414]\n",
      "0.3: [0.91023569 0.82525019 0.82758621 0.77659574 0.69112628 0.75619835\n",
      " 0.74730354 0.73355263 0.70708155 0.81355932 0.73737374 0.78412698\n",
      " 0.90904255 0.75193798 0.87472885 0.76954733 0.84722222 0.80172414]\n",
      "0.1: [0.90686869 0.83294842 0.8256705  0.75531915 0.72696246 0.75619835\n",
      " 0.74422188 0.6875     0.73712446 0.80084746 0.75869809 0.78730159\n",
      " 0.8962766  0.78294574 0.835141   0.79835391 0.82789855 0.8362069 ]\n",
      "0.07: [0.90296296 0.86297152 0.82183908 0.76595745 0.70477816 0.77272727\n",
      " 0.72727273 0.73355263 0.73175966 0.76271186 0.75196409 0.80634921\n",
      " 0.89574468 0.7751938  0.84327549 0.81069959 0.83574879 0.8362069 ]\n",
      "0.03: [0.90740741 0.8491147  0.84099617 0.75531915 0.73208191 0.76033058\n",
      " 0.75038521 0.73355263 0.75107296 0.77966102 0.7362514  0.82222222\n",
      " 0.91648936 0.7751938  0.85683297 0.80246914 0.83816425 0.84482759]\n",
      "0.01: [0.92181818 0.82140108 0.85249042 0.74468085 0.7337884  0.74793388\n",
      " 0.77812018 0.70723684 0.76716738 0.76694915 0.74410774 0.79047619\n",
      " 0.93085106 0.73643411 0.87581345 0.78600823 0.86292271 0.80172414]\n",
      "Training model 0/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 1/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 2/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 3/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 4/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 5/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 6/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 7/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 8/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n",
      "Training model 9/10, group counts: [201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201 201]\n"
     ]
    }
   ],
   "source": [
    "logreg, scaler = dfr_tune_and_run(val_embeddings, val_y_true, groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_logreg = copy.deepcopy(logreg)\n",
    "custom_logreg.intercept_ -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, custom_logreg, scaler))\n",
    "original_val_preds = torch.from_numpy(dfr_predict(original_val_embeddings, custom_logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, custom_logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.880\n",
      "  male                   acc on non_toxic: 0.850 (n =   4050)    acc on toxic: 0.815 (n =    715) \n",
      "  female                 acc on non_toxic: 0.853 (n =   5120)    acc on toxic: 0.812 (n =    771) \n",
      "  LGBTQ                  acc on non_toxic: 0.758 (n =   1099)    acc on toxic: 0.721 (n =    358) \n",
      "  christian              acc on non_toxic: 0.910 (n =   4166)    acc on toxic: 0.750 (n =    384) \n",
      "  muslim                 acc on non_toxic: 0.743 (n =   1598)    acc on toxic: 0.771 (n =    512) \n",
      "  other_religions        acc on non_toxic: 0.825 (n =    824)    acc on toxic: 0.716 (n =    162) \n",
      "  black                  acc on non_toxic: 0.727 (n =   1119)    acc on toxic: 0.779 (n =    533) \n",
      "  white                  acc on non_toxic: 0.730 (n =   2015)    acc on toxic: 0.764 (n =    852) \n",
      "Worst-group acc: 0.716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(original_val_preds, original_val_y_true, original_val_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.876\n",
      "  male                   acc on non_toxic: 0.841 (n =  12092)    acc on toxic: 0.791 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.851 (n =  14179)    acc on toxic: 0.792 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.745 (n =   3210)    acc on toxic: 0.739 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.882 (n =  12101)    acc on toxic: 0.783 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.756 (n =   5355)    acc on toxic: 0.765 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.829 (n =   2980)    acc on toxic: 0.773 (n =    520) \n",
      "  black                  acc on non_toxic: 0.740 (n =   3335)    acc on toxic: 0.753 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.736 (n =   5723)    acc on toxic: 0.776 (n =   2246) \n",
      "Worst-group acc: 0.736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.from_numpy(dfr_predict(val_embeddings, logreg, scaler))\n",
    "original_val_preds = torch.from_numpy(dfr_predict(original_val_embeddings, logreg, scaler))\n",
    "test_preds = torch.from_numpy(dfr_predict(test_embeddings, logreg, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.868\n",
      "  male                   acc on non_toxic: 0.827 (n =  12092)    acc on toxic: 0.811 (n =   2203) \n",
      "  female                 acc on non_toxic: 0.837 (n =  14179)    acc on toxic: 0.811 (n =   2270) \n",
      "  LGBTQ                  acc on non_toxic: 0.713 (n =   3210)    acc on toxic: 0.768 (n =   1216) \n",
      "  christian              acc on non_toxic: 0.869 (n =  12101)    acc on toxic: 0.809 (n =   1260) \n",
      "  muslim                 acc on non_toxic: 0.727 (n =   5355)    acc on toxic: 0.789 (n =   1627) \n",
      "  other_religions        acc on non_toxic: 0.809 (n =   2980)    acc on toxic: 0.802 (n =    520) \n",
      "  black                  acc on non_toxic: 0.715 (n =   3335)    acc on toxic: 0.785 (n =   1537) \n",
      "  white                  acc on non_toxic: 0.709 (n =   5723)    acc on toxic: 0.803 (n =   2246) \n",
      "Worst-group acc: 0.709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(test_preds, test_y_true, test_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.873\n",
      "  male                   acc on non_toxic: 0.834 (n =   4050)    acc on toxic: 0.845 (n =    715) \n",
      "  female                 acc on non_toxic: 0.837 (n =   5120)    acc on toxic: 0.829 (n =    771) \n",
      "  LGBTQ                  acc on non_toxic: 0.732 (n =   1099)    acc on toxic: 0.754 (n =    358) \n",
      "  christian              acc on non_toxic: 0.901 (n =   4166)    acc on toxic: 0.771 (n =    384) \n",
      "  muslim                 acc on non_toxic: 0.722 (n =   1598)    acc on toxic: 0.795 (n =    512) \n",
      "  other_religions        acc on non_toxic: 0.806 (n =    824)    acc on toxic: 0.728 (n =    162) \n",
      "  black                  acc on non_toxic: 0.695 (n =   1119)    acc on toxic: 0.801 (n =    533) \n",
      "  white                  acc on non_toxic: 0.700 (n =   2015)    acc on toxic: 0.795 (n =    852) \n",
      "Worst-group acc: 0.695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(original_val_preds, original_val_y_true, original_val_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc: 0.869\n",
      "  male                   acc on non_toxic: 0.823 (n =   5076)    acc on toxic: 0.800 (n =    904) \n",
      "  female                 acc on non_toxic: 0.832 (n =   6208)    acc on toxic: 0.825 (n =    991) \n",
      "  LGBTQ                  acc on non_toxic: 0.738 (n =   1199)    acc on toxic: 0.793 (n =    478) \n",
      "  christian              acc on non_toxic: 0.877 (n =   4709)    acc on toxic: 0.774 (n =    473) \n",
      "  muslim                 acc on non_toxic: 0.740 (n =   2160)    acc on toxic: 0.818 (n =    595) \n",
      "  other_religions        acc on non_toxic: 0.823 (n =   1092)    acc on toxic: 0.786 (n =    201) \n",
      "  black                  acc on non_toxic: 0.723 (n =   1349)    acc on toxic: 0.752 (n =    644) \n",
      "  white                  acc on non_toxic: 0.724 (n =   2446)    acc on toxic: 0.803 (n =    949) \n",
      "Worst-group acc: 0.723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.eval(val_preds, val_y_true, val_metadata)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9076),\n",
       " tensor(0.8661),\n",
       " tensor(0.8233),\n",
       " tensor(0.7861),\n",
       " tensor(0.7386),\n",
       " tensor(0.7897),\n",
       " tensor(0.7319),\n",
       " tensor(0.7551)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(val_preds == val_y_true)[groups == g].float().mean() for g in range(8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.get_subset(\n",
    "        \"train\",\n",
    "        frac=1.,\n",
    "        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269038"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.indices.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1108, 0.1347, 0.0313, 0.0994, 0.0519, 0.0243, 0.0368, 0.0621])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.metadata_array[:, :8].float().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d036ee486502f125a4c1259b255120961e3edf906e0a2d0ed5ed690d7b67e113"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
