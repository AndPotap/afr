{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=4\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=4\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Modify to your own data dir ###\n",
    "data_dir = '/data/users/pavel_i/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikai_q/anaconda3/envs/afr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../wilds_exps_utils/\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_eval_loader\n",
    "from wilds_configs import datasets as dataset_configs\n",
    "from wilds.datasets.wilds_dataset import WILDSSubset\n",
    "from wilds_models.initializer import initialize_model\n",
    "import wilds_transforms as transforms\n",
    "\n",
    "# from wilds_algorithms.initializer import infer_d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'civilcomments'\n",
    "\n",
    "def get_data(args, wilds_config):\n",
    "    full_dataset = get_dataset(dataset=DATASET, download=False, root_dir=args.root_dir)\n",
    "    transform = transforms.initialize_transform(\n",
    "            transform_name=wilds_config.transform,\n",
    "            config=wilds_config,\n",
    "            dataset=full_dataset,\n",
    "            additional_transform_name=None,\n",
    "            is_training=False)\n",
    "\n",
    "    test_data = full_dataset.get_subset(\"test\", transform=transform)\n",
    "    val_data = full_dataset.get_subset(\"val\", transform=transform)\n",
    "\n",
    "    if args.dfr_reweighting_drop:\n",
    "        train_data = full_dataset.get_subset(\"train\", transform=transform)\n",
    "        idx = train_data.indices.copy()\n",
    "        rng = np.random.default_rng(args.dfr_reweighting_seed)\n",
    "        rng.shuffle(idx)\n",
    "        n_train = int((1 - args.dfr_reweighting_frac) * len(idx))\n",
    "        val_idx = idx[n_train:]\n",
    "        reweighting_data = WILDSSubset(\n",
    "                full_dataset,\n",
    "                indices=val_idx,\n",
    "                transform=transform)\n",
    "        del train_data\n",
    "    else:\n",
    "        reweighting_data = val_data\n",
    "    return val_data, test_data, reweighting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just need the ds object for evaluation\n",
    "DATASET = 'civilcomments'\n",
    "seed = 2\n",
    "args = SimpleNamespace(\n",
    "    root_dir=data_dir,\n",
    "    batch_size=16,\n",
    "    dfr_reweighting_drop=True,\n",
    "    dfr_reweighting_seed=seed,\n",
    "    dfr_reweighting_frac=0.2,\n",
    "    ckpt_path=f'/home/pavel_i/projects/ssl_robustness/wilds_exps/logs/bert_civilcomments_dfrdrop_{seed}/civilcomments_seed:{seed}_epoch:last_model.pth'\n",
    ")\n",
    "wilds_config = SimpleNamespace(\n",
    "    algorithm='ERM',\n",
    "    load_featurizer_only=False,\n",
    "    pretrained_model_path=None,\n",
    "    **dataset_configs.dataset_defaults[DATASET],\n",
    ")\n",
    "wilds_config.model_kwargs = {}\n",
    "wilds_config.model = 'bert-base-uncased'\n",
    "\n",
    "val_data, test_data, reweighting_data = get_data(args, wilds_config)\n",
    "reweighting_loader = get_eval_loader(\"standard\", reweighting_data, batch_size=args.batch_size)\n",
    "val_loader = get_eval_loader(\"standard\", val_data, batch_size=args.batch_size)\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, wilds_config, d_out):\n",
    "    model = initialize_model(config=wilds_config, d_out=d_out)\n",
    "    ckpt_dict = torch.load(args.ckpt_path)\n",
    "    model.load_state_dict({k[len('model.'):]: v for (k, v) in ckpt_dict['algorithm'].items()})\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    classifier = model.classifier\n",
    "    model.classifier = torch.nn.Identity(model.classifier.in_features)\n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_predictions(feature_extractor, classifier, loader):\n",
    "    all_embeddings, all_predictions, all_y_true, all_metadata = [], [], [], []\n",
    "    # i = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y_true, metadata in tqdm.tqdm(loader):\n",
    "            embeddings = feature_extractor(x.cuda())\n",
    "            predictions = torch.argmax(classifier(embeddings), axis=1)\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_y_true.append(y_true.cpu())\n",
    "            all_metadata.append(metadata)\n",
    "    all_embeddings = torch.cat(all_embeddings, axis=0)\n",
    "    all_predictions = torch.cat(all_predictions, axis=0)\n",
    "    all_y_true = torch.cat(all_y_true, axis=0)\n",
    "    all_metadata = torch.cat(all_metadata, axis=0)\n",
    "    return all_embeddings, all_predictions, all_y_true, all_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_emb(ckpt_path, seed, save_path):\n",
    "        args = SimpleNamespace(\n",
    "        root_dir='/data/users/pavel_i/datasets/',\n",
    "        batch_size=16,\n",
    "        dfr_reweighting_drop=True,\n",
    "        dfr_reweighting_seed=seed,\n",
    "        dfr_reweighting_frac=0.2,\n",
    "        ckpt_path=ckpt_path\n",
    "        )\n",
    "        wilds_config = SimpleNamespace(\n",
    "        algorithm='ERM',\n",
    "        load_featurizer_only=False,\n",
    "        pretrained_model_path=None,\n",
    "        **dataset_configs.dataset_defaults[DATASET],\n",
    "        )\n",
    "        wilds_config.model_kwargs = {}\n",
    "        wilds_config.model = 'bert-base-uncased'\n",
    "\n",
    "        val_data, test_data, reweighting_data = get_data(args, wilds_config)\n",
    "        bad_test_idx = 73529\n",
    "        test_data.indices = np.delete(test_data.indices, bad_test_idx)\n",
    "        reweighting_loader = get_eval_loader(\"standard\", reweighting_data, batch_size=args.batch_size)\n",
    "        val_loader = get_eval_loader(\"standard\", val_data, batch_size=args.batch_size)\n",
    "        test_loader = get_eval_loader(\"standard\", test_data, batch_size=args.batch_size)\n",
    "\n",
    "        d_out = 2\n",
    "        feature_extractor, classifier = load_model(args, wilds_config, d_out)\n",
    "\n",
    "        reweighting_embeddings, reweighting_predictions, reweighting_y, reweighting_metadata = get_embeddings_predictions(\n",
    "                feature_extractor, classifier, reweighting_loader)\n",
    "        val_embeddings, val_predictions, val_y, val_metadata = get_embeddings_predictions(\n",
    "                feature_extractor, classifier, val_loader)\n",
    "        test_embeddings, test_predictions, test_y, test_metadata = get_embeddings_predictions(\n",
    "                feature_extractor, classifier, test_loader)\n",
    "        torch.save(\n",
    "        dict(\n",
    "                e=reweighting_embeddings, y=reweighting_y, pred=reweighting_predictions, m=reweighting_metadata,\n",
    "                test_e=test_embeddings, test_pred=test_predictions, test_y=test_y, test_m=test_metadata,\n",
    "                val_e=val_embeddings, val_pred=val_predictions, val_y=val_y, val_m=val_metadata,\n",
    "                w0 = classifier.weight.cpu(),\n",
    "                b0 = classifier.bias.cpu()\n",
    "        ),\n",
    "        save_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Found 0 ckpts for seed 0, expected 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[1;32m      5\u001b[0m     ckpt_path \u001b[39m=\u001b[39m glob(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mckpt_dir\u001b[39m}\u001b[39;00m\u001b[39m/bert_civilcomments_dfrdrop_\u001b[39m\u001b[39m{\u001b[39;00mseed\u001b[39m}\u001b[39;00m\u001b[39m/*last_model.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(ckpt_path) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFound \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ckpt_path)\u001b[39m}\u001b[39;00m\u001b[39m ckpts for seed \u001b[39m\u001b[39m{\u001b[39;00mseed\u001b[39m}\u001b[39;00m\u001b[39m, expected 1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m     ckpt_path \u001b[39m=\u001b[39m ckpt_path[\u001b[39m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     save_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39memb/civil/\u001b[39m\u001b[39m{\u001b[39;00mseed\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Found 0 ckpts for seed 0, expected 1"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "ckpt_dir = '/data/users/pavel_i/wilds_ckpts'\n",
    "seeds = [0, 1, 2, 3, 4, 5]\n",
    "for seed in seeds:\n",
    "    ckpt_path = glob(f'{ckpt_dir}/bert_civilcomments_dfrdrop_{seed}/*last_model.pth')\n",
    "    assert len(ckpt_path) == 1, f'Found {len(ckpt_path)} ckpts for seed {seed}, expected 1'\n",
    "    ckpt_path = ckpt_path[0]\n",
    "    save_path = f'emb/civil/{seed}.pt'\n",
    "    save_emb(ckpt_path, seed, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metrics):\n",
    "    print(\"Early stopping by Val\")\n",
    "    earlystop_epoch = np.argmax(np.array(metrics.val_accs[\"wga\"]))\n",
    "    print(f\"test WGA: {metrics.test_accs['wga'][earlystop_epoch]:.3f} at epoch {earlystop_epoch}\") \n",
    "    # print(f\"Early stopping test mean acc: {metrics.test_accs['mean_acc'][earlystop_epoch]:.3f} at epoch {earlystop_epoch}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Early stopping by Val\")\n",
    "    earlystop_epoch = np.argmax(metrics.val_accs[\"combined_wga\"])\n",
    "    print(f\"test WGA: {metrics.test_accs['wga'][earlystop_epoch]:.3f} at epoch {earlystop_epoch}\") \n",
    "    # print(f\"Early stopping test mean acc: {metrics.test_accs['mean_acc'][earlystop_epoch]:.3f} at epoch {earlystop_epoch}\")\n",
    "    print()\n",
    "    \n",
    "    # 3 horizontal subplots\n",
    "    fig, arr = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    arr[0].plot(metrics.losses, label=\"wxe\")\n",
    "    arr[0].plot(metrics.regs, label=\"Reg\")\n",
    "    arr[0].grid()\n",
    "    arr[0].legend(loc=\"lower right\")\n",
    "    arr[0].set_xlabel(\"Epochs\")\n",
    "    arr[0].set_ylabel(\"Loss\")\n",
    "\n",
    "    arr[1].plot(metrics.test_accs[\"wga\"], label=\"Test\")\n",
    "    arr[1].plot(metrics.reweighting_accs[\"wga\"], label=\"Reweighting\")\n",
    "    arr[1].plot(metrics.val_accs[\"wga\"], label=\"Validation\")\n",
    "    arr[1].grid()\n",
    "    arr[1].legend(loc=\"lower right\")\n",
    "    arr[1].set_xlabel(\"Epochs\")\n",
    "    arr[1].set_ylabel(\"WGA\")\n",
    "    arr[1].set_ylim(0.5, 0.75)\n",
    "\n",
    "    arr[2].plot(metrics.test_accs[\"mean_acc\"], label=\"Test\")\n",
    "    arr[2].plot(metrics.reweighting_accs[\"mean_acc\"], label=\"Reweighting\")\n",
    "    arr[2].plot(metrics.val_accs[\"mean_acc\"], label=\"Validation\")\n",
    "    arr[2].grid()\n",
    "    arr[2].legend(loc=\"lower right\")\n",
    "    arr[2].set_xlabel(\"Epochs\")\n",
    "    arr[2].set_ylabel(\"Mean Acc\")\n",
    "\n",
    "    # 4 horizontal subplots\n",
    "    fig, arr = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "    colors = ['r', 'g', 'b', 'y', 'm', 'c', 'k', 'orange']\n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[0, 0].plot([ls[attr] for ls in metrics.loss_by_groups['toxic']], color=c)\n",
    "        arr[0, 0].plot([ls[attr] for ls in metrics.loss_by_groups['non_toxic']], '--', color=c)\n",
    "    arr[0, 0].grid()\n",
    "    arr[0, 0].set_xlabel(\"Epochs\")\n",
    "    arr[0, 0].set_ylabel(\"Loss\")\n",
    "    arr[0, 0].legend(loc=\"lower right\")\n",
    "\n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[0, 1].plot([ls[attr] for ls in metrics.weights_by_groups['toxic']], color=c)\n",
    "        arr[0, 1].plot([ls[attr] for ls in metrics.weights_by_groups['non_toxic']], '--', color=c)\n",
    "    arr[0, 1].grid()\n",
    "    arr[0, 1].set_xlabel(\"Epochs\")\n",
    "    arr[0, 1].set_ylabel(\"Weights\")\n",
    "    arr[0, 1].legend(loc=\"lower right\")\n",
    "\n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[0, 2].plot([ls[attr] for ls in metrics.confidence_by_groups['toxic']], color=c)\n",
    "        arr[0, 2].plot([ls[attr] for ls in metrics.confidence_by_groups['non_toxic']], '--', color=c)\n",
    "    arr[0, 2].grid()\n",
    "    arr[0, 2].set_xlabel(\"Epochs\")\n",
    "    arr[0, 2].set_ylabel(\"Confidence\")\n",
    "    arr[0, 2].legend(loc=\"lower right\")\n",
    "\n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[1, 0].plot([ls[attr] for ls in metrics.test_accs['by_group_toxic']], color=c)\n",
    "        arr[1, 0].plot([ls[attr] for ls in metrics.test_accs['by_group_nontoxic']], '--', color=c)\n",
    "    arr[1, 0].plot(metrics.test_accs['combined_wga'], '-*', color='k')\n",
    "    arr[1, 0].grid()\n",
    "    arr[1, 0].set_xlabel(\"Epochs\")\n",
    "    arr[1, 0].set_ylabel(\"Test Acc\")\n",
    "    arr[1, 0].legend(loc=\"lower right\")\n",
    "    \n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[1, 1].plot([ls[attr] for ls in metrics.val_accs['by_group_toxic']], color=c)\n",
    "        arr[1, 1].plot([ls[attr] for ls in metrics.val_accs['by_group_nontoxic']], '--', color=c)\n",
    "    arr[1, 1].plot(metrics.val_accs['combined_wga'], '-*', color='k')\n",
    "    arr[1, 1].grid()\n",
    "    arr[1, 1].set_xlabel(\"Epochs\")\n",
    "    arr[1, 1].set_ylabel(\"Val Acc\")\n",
    "    arr[1, 1].legend(loc=\"lower right\")\n",
    "    \n",
    "    for attr, c in enumerate(colors):\n",
    "        arr[1, 2].plot([ls[attr] for ls in metrics.reweighting_accs['by_group_toxic']], color=c)\n",
    "        arr[1, 2].plot([ls[attr] for ls in metrics.reweighting_accs['by_group_nontoxic']], '--', color=c)\n",
    "    arr[1, 2].plot(metrics.reweighting_accs['combined_wga'], '-*', color='k')\n",
    "    arr[1, 2].grid()\n",
    "    arr[1, 2].set_xlabel(\"Epochs\")\n",
    "    arr[1, 2].set_ylabel(\"Reweighting Acc\")\n",
    "    arr[1, 2].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    def __init__(\n",
    "            self, reweighting_metadata, test_metadata, val_metadata):\n",
    "        \n",
    "        self.n_cols = 8\n",
    "        \n",
    "        self.reweighting_metadata = reweighting_metadata\n",
    "        self.test_metadata = test_metadata\n",
    "        self.val_metadata = val_metadata\n",
    "        \n",
    "        self.reweighting_accs = self.get_init_accs()\n",
    "        self.test_accs = self.get_init_accs()\n",
    "        self.val_accs = self.get_init_accs()\n",
    "        \n",
    "        self.weights_by_groups = self.get_init_dict()\n",
    "        self.loss_by_groups = self.get_init_dict()\n",
    "        self.confidence_by_groups = self.get_init_dict()\n",
    "        \n",
    "        keys = (\"toxic\", \"non_toxic\")\n",
    "        self.reweighting_group_sizes = dict(zip(keys, self._something_by_groups(\n",
    "                torch.ones_like(reweighting_metadata[:, 0]), reweighting_metadata)))\n",
    "        self.val_group_sizes = dict(zip(keys, self._something_by_groups(\n",
    "                torch.ones_like(val_metadata[:, 0]), val_metadata)))\n",
    "        self.test_group_sizes = dict(zip(keys, self._something_by_groups(\n",
    "                torch.ones_like(test_metadata[:, 0]), test_metadata)))\n",
    "        \n",
    "        self.losses = []\n",
    "        self.regs = []\n",
    "        \n",
    "#         self.weighted_acc = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_init_dict():\n",
    "        return {'toxic': [], 'non_toxic': []}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_init_accs():\n",
    "        return {\n",
    "            'mean_acc': [],\n",
    "            'wga': [],\n",
    "            'combined_wga': [],\n",
    "            'by_group_toxic': [],\n",
    "            'by_group_nontoxic': []\n",
    "        }\n",
    "    \n",
    "    def _something_by_groups(self, something, metadata, mean=False):\n",
    "        if mean: \n",
    "            return (\n",
    "                [something[(metadata[:, i] == 1) & (metadata[:, -2] == v)].float().mean().item() for i in range(self.n_cols)]\n",
    "                for v in [0, 1])\n",
    "        else:\n",
    "            return (\n",
    "                [something[(metadata[:, i] == 1) & (metadata[:, -2] == v)].sum().item() for i in range(self.n_cols)]\n",
    "                for v in [0, 1])\n",
    "    \n",
    "    def _update_weights_by_groups(self, weights):\n",
    "        toxic, nontoxic = self._something_by_groups(\n",
    "            weights, self.reweighting_metadata)\n",
    "        self.weights_by_groups['toxic'].append(toxic)\n",
    "        self.weights_by_groups['non_toxic'].append(nontoxic)\n",
    "    \n",
    "    def _update_loss_by_groups(self, ce):\n",
    "        toxic, nontoxic = self._something_by_groups(\n",
    "            ce, self.reweighting_metadata)\n",
    "        self.loss_by_groups['toxic'].append(toxic)\n",
    "        self.loss_by_groups['non_toxic'].append(nontoxic)\n",
    "    \n",
    "    def _update_confidence_by_groups(self, p_true):\n",
    "        toxic, nontoxic = self._something_by_groups(\n",
    "            p_true, self.reweighting_metadata, mean=True)\n",
    "        self.confidence_by_groups['toxic'].append(toxic)\n",
    "        self.confidence_by_groups['non_toxic'].append(nontoxic)\n",
    "    \n",
    "    def _update_accs(self, accs, metadata, results, predictions):\n",
    "        toxic, nontoxic = self._something_by_groups(predictions == metadata[:, -2], metadata, mean=True)\n",
    "        accs['mean_acc'].append(results[0]['acc_avg'])\n",
    "        accs['wga'].append(results[0]['acc_wg'])\n",
    "        accs['by_group_toxic'].append(toxic)\n",
    "        accs['by_group_nontoxic'].append(nontoxic)\n",
    "        all_accs = np.array([toxic, nontoxic])\n",
    "        weights = np.array([0.56, 0.29, 0.15])[None, :]\n",
    "        all_accs = np.hstack([\n",
    "            all_accs[:, :3], \n",
    "            np.sum(all_accs[:, 3:6] * weights , axis=1, keepdims=True),\n",
    "            all_accs[:, 6:]])\n",
    "        accs['combined_wga'].append(np.min(all_accs))\n",
    "\n",
    "   \n",
    "    def update(\n",
    "            self, weights, ce, p_true, loss, reg,\n",
    "            reweighting_results, reweighting_predictions,\n",
    "            test_results, test_predictions, \n",
    "            val_results, val_predictions\n",
    "        ):\n",
    "        \n",
    "        self._update_weights_by_groups(weights)\n",
    "        self._update_loss_by_groups(ce)\n",
    "        self._update_confidence_by_groups(p_true)\n",
    "        \n",
    "        self._update_accs(self.reweighting_accs, self.reweighting_metadata, reweighting_results, reweighting_predictions)\n",
    "        self._update_accs(self.test_accs, self.test_metadata, test_results, test_predictions)\n",
    "        self._update_accs(self.val_accs, self.val_metadata, val_results, val_predictions)\n",
    "        \n",
    "        self.losses.append(loss.item())\n",
    "        self.regs.append(reg.item())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wxe(*_):\n",
    "    def confidence_wxe_fn(logits, y, weights):\n",
    "        ce = torch.nn.functional.cross_entropy(logits, y, reduction='none')\n",
    "        focal = weights * ce\n",
    "        return focal.sum(), weights\n",
    "\n",
    "    return confidence_wxe_fn\n",
    "\n",
    "def compute_weights(logits, reweighting_y, gamma, balance_classes, base_weights=0.):\n",
    "    with torch.no_grad():\n",
    "        p = logits.softmax(-1)\n",
    "        y_onehot = torch.zeros_like(logits).scatter_(-1, reweighting_y.unsqueeze(-1), 1)\n",
    "        p_true = (p * y_onehot).sum(-1)\n",
    "        weights = (-gamma * p_true).exp()\n",
    "        if balance_classes:\n",
    "            w1 = (reweighting_y == 0).sum()\n",
    "            w2 = (reweighting_y == 1).sum()\n",
    "            weights[reweighting_y == 0] *= w2 / w1\n",
    "        weights = weights.detach()\n",
    "        weights /= weights.sum()\n",
    "        weights += base_weights / len(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        reweighting_data, test_data, val_data,\n",
    "        emb_dict, num_epochs, gamma, reg_coeff, lr=1e-2,\n",
    "        base_weights=0.,\n",
    "        balance_classes=False, plot=True, silent=False, combine_reweighting=False):\n",
    "\n",
    "    del plot\n",
    "    \n",
    "    reweighting_embeddings = emb_dict['e'].cuda()\n",
    "    reweighting_y = emb_dict['y'].cuda()\n",
    "    reweighting_metadata = emb_dict['m'].cuda()\n",
    "    test_embeddings = emb_dict['test_e'].cuda()\n",
    "    test_y = emb_dict['test_y'].cuda()\n",
    "    test_metadata = emb_dict['test_m'].cuda()\n",
    "    val_embeddings = emb_dict['val_e'].cuda()\n",
    "    val_y = emb_dict['val_y'].cuda()\n",
    "    val_metadata = emb_dict['val_m'].cuda()\n",
    "    w0 = emb_dict['w0'].cuda()\n",
    "    b0 = emb_dict['b0'].cuda()\n",
    "    \n",
    "    if combine_reweighting:\n",
    "        reweighting_embeddings = torch.cat([reweighting_embeddings, val_embeddings])\n",
    "        reweighting_y = torch.cat([reweighting_y, val_y])\n",
    "        reweighting_metadata = torch.cat([reweighting_metadata, val_metadata])\n",
    "    print(\"Reweighting size:\", len(reweighting_y))\n",
    "    \n",
    "    # Early stopping\n",
    "    best_weights = {'w': w0, 'b': b0}\n",
    "    best_wga = 0\n",
    "#     trian_group_ratios = emb_dict['trian_group_ratios']\n",
    "\n",
    "    last_layer_model = torch.nn.Linear(w0.shape[1], w0.shape[0], bias=True)\n",
    "    last_layer_model.weight.data = w0.clone()\n",
    "    last_layer_model.bias.data = b0.clone()\n",
    "    last_layer_model.cuda()\n",
    "\n",
    "    criterion = get_wxe(gamma)\n",
    "    optimizer = torch.optim.SGD(last_layer_model.parameters(), lr=lr, weight_decay=0., momentum=0.)\n",
    "\n",
    "    metrics = Metrics(reweighting_metadata, test_metadata, val_metadata)\n",
    "\n",
    "    initial_logits = last_layer_model(reweighting_embeddings)\n",
    "    weights = compute_weights(initial_logits, reweighting_y, gamma, balance_classes, base_weights=base_weights)\n",
    "\n",
    "    for epoch in (pbar := tqdm.tqdm(range(num_epochs), disable=silent)):\n",
    "        optimizer.zero_grad()\n",
    "        logits = last_layer_model(reweighting_embeddings)\n",
    "        loss, _ = criterion(logits, reweighting_y, weights)\n",
    "\n",
    "        # L2 penalty for deviation from model.fc.weight and model.fc.bias\n",
    "        reg = ((last_layer_model.weight - w0).pow(2).sum() + (last_layer_model.bias - b0).pow(2).sum())\n",
    "        loss += reg_coeff * reg\n",
    "\n",
    "        # additional infos\n",
    "        with torch.no_grad():\n",
    "            ce = torch.nn.functional.cross_entropy(logits, reweighting_y, reduction='none')\n",
    "            p_true = (logits.softmax(-1) * torch.nn.functional.one_hot(reweighting_y, 2)).sum(-1)\n",
    "            \n",
    "            reweighting_predictions = torch.argmax(logits, -1)\n",
    "            test_predictions = torch.argmax(last_layer_model(test_embeddings), -1)\n",
    "            val_predictions = torch.argmax(last_layer_model(val_embeddings), -1)\n",
    "            reweighting_results = reweighting_data.eval(\n",
    "                    reweighting_predictions.cpu(), reweighting_y.cpu(), reweighting_metadata.cpu())\n",
    "            test_results = test_data.eval(test_predictions.cpu(), test_y.cpu(), test_metadata.cpu())\n",
    "            val_results = val_data.eval(val_predictions.cpu(), val_y.cpu(), val_metadata.cpu())\n",
    "        \n",
    "        metrics.update(\n",
    "            weights, ce, p_true, loss, reg,\n",
    "            reweighting_results, reweighting_predictions,\n",
    "            test_results, test_predictions, \n",
    "            val_results, val_predictions\n",
    "        )\n",
    "        \n",
    "        wga = metrics.val_accs['combined_wga'][-1]\n",
    "        if wga > best_wga:\n",
    "            best_wga = wga\n",
    "            best_weights = {'w': last_layer_model.weight.data.clone(), 'b': last_layer_model.bias.data.clone()}\n",
    "\n",
    "        nzw = (weights != 0).float().mean()\n",
    "        loss.backward()\n",
    "        # clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(last_layer_model.parameters(), 1.)\n",
    "        optimizer.step()\n",
    "    #     scheduler.step()\n",
    "\n",
    "        wga = metrics.reweighting_accs[\"wga\"][-1]\n",
    "        test_wga = metrics.test_accs[\"wga\"][-1]\n",
    "        pbar.set_description(f\"Val cwga: {best_wga:.3f}, TWGA: {test_wga:.3f}\")\n",
    "\n",
    "    return metrics, best_weights, best_wga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_size_adjusted_wga(accs, sizes, i):\n",
    "    at, st = np.array(accs[\"by_group_toxic\"][i]), np.array(sizes[\"toxic\"])\n",
    "    an, sn = np.array(accs[\"by_group_nontoxic\"][i]), np.array(sizes[\"non_toxic\"])\n",
    "    vt, vn = at - at**2, an - an**2\n",
    "    lbs = np.concatenate([at - np.sqrt(vt / st), an - np.sqrt(vn / sn)])\n",
    "    return np.min(lbs)\n",
    "\n",
    "def wga(accs, i):\n",
    "    at = np.array(accs[\"by_group_toxic\"][i])\n",
    "    an = np.array(accs[\"by_group_nontoxic\"][i])\n",
    "    return np.min(np.concatenate([at, an]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twga(metrics):\n",
    "    earlystop_epoch = np.argmax(metrics.val_accs[\"combined_wga\"])\n",
    "    return metrics.test_accs['wga'][earlystop_epoch]\n",
    "\n",
    "def twga_last(metrics):\n",
    "    earlystop_epoch = -1\n",
    "    return metrics.test_accs['wga'][earlystop_epoch]\n",
    "\n",
    "def vwga(metrics):\n",
    "    earlystop_epoch = np.argmax(metrics.val_accs[\"wga\"])\n",
    "    return metrics.val_accs['wga'][earlystop_epoch]\n",
    "\n",
    "def vwga_last(metrics):\n",
    "    earlystop_epoch = -1\n",
    "    return metrics.val_accs['wga'][earlystop_epoch]\n",
    "\n",
    "def vcwga(metrics):\n",
    "    earlystop_epoch = np.argmax(metrics.val_accs[\"combined_wga\"])\n",
    "    return metrics.val_accs['combined_wga'][earlystop_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighting size: 53808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val cwga: 0.000, TWGA: 0.421: 100%|██████████| 50/50 [00:08<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, gamma 0.0, reg 0, lr 0.01: 0\n",
      "Reweighting size: 53808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val cwga: 0.000, TWGA: 0.420: 100%|██████████| 50/50 [00:08<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, gamma 0.001, reg 0, lr 0.01: 0\n",
      "Reweighting size: 53808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val cwga: 0.000, TWGA: 0.419: 100%|██████████| 50/50 [00:07<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, gamma 0.01, reg 0, lr 0.01: 0\n",
      "Reweighting size: 53808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val cwga: 0.000, TWGA: 0.399: 100%|██████████| 50/50 [00:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, gamma 0.1, reg 0, lr 0.01: 0\n",
      "Reweighting size: 53808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val cwga: 0.000, TWGA: 0.558:  46%|████▌     | 23/50 [00:02<00:03,  8.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m reg_coef \u001b[39min\u001b[39;00m reg_coefs:\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m lr \u001b[39min\u001b[39;00m lrs:\n\u001b[0;32m---> 22\u001b[0m         metrics, weights, val_wga \u001b[39m=\u001b[39m train(\n\u001b[1;32m     23\u001b[0m                 reweighting_data, test_data, val_data,\n\u001b[1;32m     24\u001b[0m                 emb_dict, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, gamma\u001b[39m=\u001b[39;49mgamma, reg_coeff\u001b[39m=\u001b[39;49mreg_coef, lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m     25\u001b[0m                 balance_classes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, plot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, silent\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, combine_reweighting\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     26\u001b[0m         all_results[(val_prop, shuffle_seed, seed, gamma, reg_coef, lr)] \u001b[39m=\u001b[39m val_wga\n\u001b[1;32m     27\u001b[0m         all_metrics[(val_prop, shuffle_seed, seed, gamma, reg_coef, lr)] \u001b[39m=\u001b[39m metrics\n",
      "Cell \u001b[0;32mIn[17], line 64\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     61\u001b[0m     val_predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(last_layer_model(val_embeddings), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m     reweighting_results \u001b[39m=\u001b[39m reweighting_data\u001b[39m.\u001b[39meval(\n\u001b[1;32m     63\u001b[0m             reweighting_predictions\u001b[39m.\u001b[39mcpu(), reweighting_y\u001b[39m.\u001b[39mcpu(), reweighting_metadata\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m---> 64\u001b[0m     test_results \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39;49meval(test_predictions\u001b[39m.\u001b[39;49mcpu(), test_y\u001b[39m.\u001b[39;49mcpu(), test_metadata\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     65\u001b[0m     val_results \u001b[39m=\u001b[39m val_data\u001b[39m.\u001b[39meval(val_predictions\u001b[39m.\u001b[39mcpu(), val_y\u001b[39m.\u001b[39mcpu(), val_metadata\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     67\u001b[0m metrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m     68\u001b[0m     weights, ce, p_true, loss, reg,\n\u001b[1;32m     69\u001b[0m     reweighting_results, reweighting_predictions,\n\u001b[1;32m     70\u001b[0m     test_results, test_predictions, \n\u001b[1;32m     71\u001b[0m     val_results, val_predictions\n\u001b[1;32m     72\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/afr/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py:522\u001b[0m, in \u001b[0;36mWILDSSubset.eval\u001b[0;34m(self, y_pred, y_true, metadata)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, y_pred, y_true, metadata):\n\u001b[0;32m--> 522\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49meval(y_pred, y_true, metadata)\n",
      "File \u001b[0;32m~/anaconda3/envs/afr/lib/python3.9/site-packages/wilds/datasets/civilcomments_dataset.py:164\u001b[0m, in \u001b[0;36mCivilCommentsDataset.eval\u001b[0;34m(self, y_pred, y_true, metadata, prediction_fn)\u001b[0m\n\u001b[1;32m    162\u001b[0m worst_group_metric \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39mfor\u001b[39;00m identity_var, eval_grouper \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_identity_vars, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_groupers):\n\u001b[0;32m--> 164\u001b[0m     g \u001b[39m=\u001b[39m eval_grouper\u001b[39m.\u001b[39;49mmetadata_to_group(metadata)\n\u001b[1;32m    165\u001b[0m     group_results \u001b[39m=\u001b[39m {\n\u001b[1;32m    166\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmetric\u001b[39m.\u001b[39mcompute_group_wise(y_pred, y_true, g, eval_grouper\u001b[39m.\u001b[39mn_groups)\n\u001b[1;32m    167\u001b[0m     }\n\u001b[1;32m    168\u001b[0m     results_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00midentity_var\u001b[39m:\u001b[39;00m\u001b[39m20s\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/afr/lib/python3.9/site-packages/wilds/common/grouper.py:153\u001b[0m, in \u001b[0;36mCombinatorialGrouper.metadata_to_group\u001b[0;34m(self, metadata, return_counts)\u001b[0m\n\u001b[1;32m    151\u001b[0m     groups \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(metadata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     groups \u001b[39m=\u001b[39m metadata[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroupby_field_indices]\u001b[39m.\u001b[39mlong() \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactors\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m return_counts:\n\u001b[1;32m    156\u001b[0m     group_counts \u001b[39m=\u001b[39m get_counts(groups, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_groups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gammas = [0., 0.001, 0.01, 0.1, 1., 10., 100.]\n",
    "reg_coefs = [0]\n",
    "lrs = [1e-2]\n",
    "\n",
    "all_results = {}\n",
    "all_metrics = {}\n",
    "\n",
    "for val_prop in [0.005]: #[0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]:\n",
    "    for seed in seeds:\n",
    "        for shuffle_seed in [0, 21, 42]:\n",
    "            rng = np.random.default_rng(shuffle_seed)\n",
    "            emb_dict = torch.load(f\"../emb/civil/{seed}.pt\")\n",
    "            idx = np.arange(len(emb_dict['val_y']))\n",
    "            rng.shuffle(idx)\n",
    "            idx = idx[:int(val_prop * len(idx))]\n",
    "            emb_dict['val_y'] = emb_dict['val_y'][idx]\n",
    "            emb_dict['val_e'] = emb_dict['val_e'][idx]\n",
    "            emb_dict['val_m'] = emb_dict['val_m'][idx]\n",
    "            for gamma in gammas:\n",
    "                for reg_coef in reg_coefs:\n",
    "                    for lr in lrs:\n",
    "                        metrics, weights, val_wga = train(\n",
    "                                reweighting_data, test_data, val_data,\n",
    "                                emb_dict, num_epochs=50, gamma=gamma, reg_coeff=reg_coef, lr=lr,\n",
    "                                balance_classes=True, plot=False, silent=False, combine_reweighting=False)\n",
    "                        all_results[(val_prop, shuffle_seed, seed, gamma, reg_coef, lr)] = val_wga\n",
    "                        all_metrics[(val_prop, shuffle_seed, seed, gamma, reg_coef, lr)] = metrics\n",
    "                        print(f\"seed {seed}, gamma {gamma}, reg {reg_coef}, lr {lr}: {val_wga}\")\n",
    "# save all_metrics\n",
    "torch.save(all_metrics, \"all_metrics.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = torch.load(\"all_metrics.pt\")\n",
    "seeds = [0,1,2,3,4]\n",
    "vps = [0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "test_wgas = []\n",
    "for val_prop in vps:\n",
    "    twgas = []\n",
    "    for seed in seeds[:5]:\n",
    "        seed_metrics = {k: v for (k, v) in all_metrics.items() if k[0] == val_prop and k[2] == seed}\n",
    "        max_key = max(seed_metrics, key=lambda k: vcwga(seed_metrics[k]))\n",
    "        twgas.append(twga(all_metrics[max_key]))\n",
    "    test_wgas.append(twgas)\n",
    "    print(val_prop, np.mean(twgas), np.std(twgas))\n",
    "\n",
    "mean_wgas = [np.mean(twgas) for twgas in test_wgas]\n",
    "std_wgas = [np.std(twgas) for twgas in test_wgas]\n",
    "mean_wgas = np.array(mean_wgas) * 100\n",
    "std_wgas = np.array(std_wgas) * 100\n",
    "vps = np.array(vps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "dfr_vps = []\n",
    "dfr_wgas = []\n",
    "for file in glob('/home/shikai_q/deep_feature_reweighting/results/dfr_civil*.pkl'):\n",
    "    with open(file, 'rb') as f:\n",
    "        dfr = pickle.load(f)\n",
    "    dfr_vps = dfr['val_fracs']\n",
    "    dfr_wgas.append(dfr['test_wgas']) # (vp, seed)\n",
    "dfr_vps = np.array(dfr_vps)\n",
    "dfr_wgas = np.array(dfr_wgas) # (ckpt, vp, seed)\n",
    "dfr_mean_wgas = np.mean(dfr_wgas, axis=(0, 2)) * 100 # (vp, )\n",
    "dfr_std_wgas = np.std(dfr_wgas, axis=(0, 2)) * 100 # (vp, )\n",
    "\n",
    "# plot mean and std against val_props\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale=2.0, rc={\"lines.linewidth\": 3.0})\n",
    "sns.set_palette(\"Set1\")\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 6))\n",
    "erm = 57.4\n",
    "plt.plot([0, 1], [erm, erm], '--', label='ERM', color='black')\n",
    "\n",
    "# plot nice-looking error bars as shaded region\n",
    "plt.fill_between(vps, mean_wgas - std_wgas, mean_wgas + std_wgas, alpha=0.2)\n",
    "plt.plot(vps, mean_wgas, label='AFR', marker='o', markersize=10)\n",
    "\n",
    "plt.plot(dfr_vps[dfr_vps >= vps.min()], dfr_mean_wgas[dfr_vps >= vps.min()], label='DFR', marker='o', markersize=10)\n",
    "plt.fill_between(dfr_vps[dfr_vps >= vps.min()], dfr_mean_wgas[dfr_vps >= vps.min()] - dfr_std_wgas[dfr_vps >= vps.min()], dfr_mean_wgas[dfr_vps >= vps.min()] + dfr_std_wgas[dfr_vps >= vps.min()], alpha=0.2)\n",
    "plt.xlabel('Fraction of group labels')\n",
    "# log x axis but label in linear\n",
    "plt.xscale('log')\n",
    "ticks = vps\n",
    "plt.xticks(ticks, ticks, fontsize=20)\n",
    "\n",
    "plt.ylabel('Test WGA [%]')\n",
    "plt.legend(loc='lower right', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/civil_dfr_eff.pdf')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
